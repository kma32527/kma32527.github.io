## Model details

## Basis
Given the assumption that the contents of a paper is valid, one can consider a paper to be a bag of concepts, where concepts are represented by an ordered set of words. I use binary variables from ngrams representing inclusion in a text. This is in an effort to remove author bias when discussing the contents of a paper, since authors discuss their personal interests in more depth and detail. By standardizing the feature extraction  binary inclusion variables, the model evenly weights all concepts that an author brings up.

### Filtering for mathematical terminology
Scientific models incorporate math because it is demonstrably a good representation. However, these mathematical models are more than just a good representation; they also can provide insight into the underlying *dynamics*. By discussing the mathematics at all, authors establish a relation between words associated with a scientific concept and words associated with a representative mathematical structure. This can be picked up on in a naive manner with a bag of words model, since academic terminology favours precision over brevity. Furthermore, using a binary 'term-presence' feature representation reduces the author's personal bias towards or against a mathematical model, instead conditioning on the *existence* of a given connections between math and science. I believe that this has potential for identifying broad, interdisciplinary trends in the existing literature.
